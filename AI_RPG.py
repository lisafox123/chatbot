from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from rich import print as pprint
from langchain_mistralai import ChatMistralAI
import os
import getpass
from langgraph.graph import START, StateGraph,END
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.messages import SystemMessage, ToolMessage, AIMessage, HumanMessage
from typing_extensions import TypedDict
import json
import random
import streamlit as st
# è¨­å®šAPI Key
def mistral_key(api_key=None):
    if api_key:
        os.environ["MISTRAL_API_KEY"] = api_key
    else:
        os.environ["MISTRAL_API_KEY"] = getpass("Tavily API key:\n")

# å¾ secrets.toml è®€å–
api_key = st.secrets["MISTRAL_API_KEY"]
mistral_key(api_key)
# åˆå§‹åŒ–æ¨¡å‹
llm = ChatMistralAI(
    model="mistral-large-latest",
    temperature=0,
    max_retries=2,
)

from bs4 import BeautifulSoup
from typing import Dict
import requests as rq
import re
def get_newsongs(token):
    url = "https://api.spotify.com/v1/search"
    headers = { "Authorization": f"Bearer {token}"}
    # genre:rock
    params = {"q":"one ok rock","market":"TW","type":"track","limit": 10}
    response = rq.get(url, headers=headers, params=params)
    search_results = response.json()
    print(search_results)
    search = search_results['tracks']['items']
    uri = []
    name = []
    num = random.randint(0,10)
    for result in search:
        if result:  # æª¢æŸ¥ playlist æ˜¯å¦ç‚º None
                name.append(result.get('name'))
                uri.append(result["uri"])
        else:
            print("Playlist is None.")
    return name[num],uri[num]


def get_token():
    token_url = "https://accounts.spotify.com/api/token"
    headers = {
    "Content-Type": "application/x-www-form-urlencoded"
    }
    data = {
        "grant_type": "client_credentials",
        "client_id": "fe6ef6c3ecf84073a8afdd24fefafb34",
        "client_secret": "9205fe50d23146ac888b6ab5e7167dd4",
    }
    response = rq.post(token_url, headers=headers, data=data)
    token_info = response.json()['access_token']
    return token_info

# get_newsongs(token = get_token())

def play(token,uri):
    headers = { "Authorization": f"Bearer {token}"}
    device_response = rq.get("https://api.spotify.com/v1/me/player/devices", headers=headers)
    url = "https://api.spotify.com/v1/me/player/play"
    data = {
    "uris": uri }

    response = rq.put(url, headers=headers, json=data)

    if response.status_code == 204:
        return("æˆåŠŸé–‹å§‹æ’­æ”¾ ğŸ¶")
    else:
        return("æ’­æ”¾å¤±æ•—:", response.json())
    
def clean_text(text):
    return re.sub(r"[^\w\u4e00-\u9fff]", "", text)
def get_lyrics_azlyrics(artist, song):
    artist = clean_text(artist.replace(" ", "").lower())
    song = clean_text(song.replace(" ", "").lower())
    
    url = f"https://www.azlyrics.com/lyrics/{artist}/{song}.html"
    headers = {"User-Agent": "Mozilla/5.0"}
    
    response = rq.get(url, headers=headers)
    if response.status_code != 200:
        return "æ­Œè©æœªæ‰¾åˆ°"

    soup = BeautifulSoup(response.text, "html.parser")
    br_tags = soup.find_all("br")
    # æå– <br> æ¨™ç±¤å‰çš„æ–‡å­—
    br_texts = [
    br.previous_sibling.strip()
    for br in br_tags
    if br.previous_sibling and isinstance(br.previous_sibling, str)
    ]
    # é¡¯ç¤ºçµæœ
    br_texts = " ".join(br_texts)
    return br_texts

# æ¸¬è©¦

class GraphState(TypedDict):
    question: str
    lyrics:str
    story:str
    chat_history:list[str]

def first_router(state):
    chat_history = state["chat_history"]
    question = state["question"]
    template = ChatPromptTemplate([
    ("system", """ä½ æ˜¯ä¸€å€‹å–„æ–¼åˆ†è¾¨å•é¡Œçš„routerï¼Œæ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œä»¥åŠèŠå¤©ç´€éŒ„
     åˆ†è¾¨å•é¡Œæ‡‰è©²è¦è‡ªè¡Œå›ç­”é‚„æ˜¯å°å‘ä¸‹ä¸€å€‹è·¯å¾‘
     ### **è¼¸å‡ºæ ¼å¼**
    jsonï¼š{{"datasource": "<yes | no>"}}"""),
    ("human", """æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œ{question}ï¼Œä»¥åŠæ­·å²ç´€éŒ„ï¼š{chat_history}ä¾†åˆ†é…è·¯å¾‘ã€‚
     è‹¥ä½¿ç”¨è€…çš„å•é¡Œèˆ‡æƒ…ç·’ç„¡é—œ(ä¾‹å¦‚ï¼šè©¢å•æ­·å²ç´€éŒ„ç›¸é—œå…§å®¹)ï¼Œ- åƒ…è¿”å› JSON: {{ "datasource": "no" }}
     è‹¥ä½¿ç”¨è€…çš„å•é¡Œèˆ‡æƒ…ç·’æœ‰é—œæˆ–æƒ³è¦æ¨è–¦æ­Œæ›²ï¼Œ- åƒ…è¿”å› JSON: {{ "datasource": "yes" }}"""
)])
    prompt_value = llm.invoke(
    {
        "question": question,
        "chat_history": chat_history
    }
)
    source = json.loads(source.content)["datasource"]
    print(source)
    if source == "yes":
        return "yes"
    else:
        return "no"
def general(state):
    question = state["question"]

    
def route_question(state):
    """
    åˆ†è¾¨å•é¡Œçš„å»å‘(ä»¥æª¢ç´¢ç‚ºä¸»)
    """
    print("---ROUTE QUESTION---")
    question = state["question"]
    router_instructions = """
    ä½ æ˜¯ä¸€å€‹å–„æ–¼åˆ†è¾¨æ–‡å­—æƒ…ç·’çš„å°ˆå®¶ã€‚
    è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¨Šæ¯æƒ…ç·’é¸æ“‡è¦æ¨è–¦ä»€éº¼é¡å‹çš„æ­Œçµ¦ä»–ã€‚
    å¿…è¦æ™‚æª¢ç´¢èŠå¤©ç´€éŒ„å–å¾—è³‡è¨Šã€‚
    - **å‘é‡è³‡æ–™åº«ï¼ˆvectorstoreï¼‰**ï¼šåŒ…å«æ‰€æœ‰èŠå¤©ç´€éŒ„å–å¾—ä½¿ç”¨è€…è³‡è¨Šã€‚  
    - **æ–°çš„æ­Œæ›²ï¼ˆnewï¼‰**ï¼šç•¶ä½¿ç”¨è€…æƒ³è¦å‰µæ–°ä¸€é»æˆ–ç‰¹å®šæƒ…ç·’çš„æ­Œæ™‚ã€‚  
    - **å–œæ­¡çš„æ­Œï¼ˆlikeï¼‰**ï¼šç•¶ä½¿ç”¨è€…æŒ‡å®šè¦è‡ªå·±å–œæ­¡çš„æ­Œæ™‚ã€‚  
    !ä¸è¦åŒ…å«é¢å¤–çš„æ¨ç†æˆ–è§£é‡Šã€‚ä¸“æ³¨äºè¯†åˆ«å›ç­”ç”¨æˆ·é—®é¢˜çš„æ–‡æ¡£ã€‚
    
    ### **è¼¸å‡ºæ ¼å¼**
    jsonï¼š{{"datasource": "<vectorstore | new | like>"}}

    **è«‹ç¢ºä¿è¼¸å‡ºåªæœ‰ JSONï¼Œé¿å…ä»»ä½•é¡å¤–è§£é‡‹æˆ–é JSON å…§å®¹ã€‚**
    """
    router_prompt = """
    ä½¿ç”¨è€…çš„å•é¡Œï¼š{question}
    æ ¹æ“šä½¿ç”¨è€…çš„è¨Šæ¯ï¼Œé¸æ“‡è¦æª¢ç´¢èŠå¤©ç´€éŒ„äº†è§£å•é¡Œï¼Œé‚„æ˜¯ç›´æ¥å¾å•é¡Œäº†è§£ä½¿ç”¨è€…æƒ…ç·’ã€‚
    ä½ çš„å›æ‡‰å¿…é ˆæ˜¯ **æ¨™æº– JSON æ ¼å¼**ï¼Œç„¡å¤šé¤˜å…§å®¹ï¼Œä¾‹å¦‚ï¼š
    1. **èŠå¤©ç´€éŒ„å–å¾—ä½¿ç”¨è€…è³‡è¨Š**ï¼š  
       - åƒ…è¿”å› JSON: {{ "datasource": "vectorstore" }}

    2. **å‰µæ–°çš„æ­Œæ›²åˆ†äº«**ï¼ˆä½¿ç”¨è€…æƒ³è¦å‰µæ–°ä¸€é»æˆ–ç‰¹å®šæƒ…ç·’çš„æ­Œæ™‚ï¼‰ï¼š  
       - åƒ…è¿”å› JSON: {{ "datasource": "new" }}

    3. **å–œæ­¡çš„æ­Œ**ï¼ˆä½¿ç”¨è€…æŒ‡å®šè¦è‡ªå·±å–œæ­¡çš„æ­Œæ™‚ï¼‰ï¼š  
       - åƒ…è¿”å› JSON: {{ "datasource": "like" }}

    - **è«‹ç¢ºä¿å›æ‡‰æ ¼å¼åš´æ ¼éµå®ˆ JSON æ¨™æº–ï¼Œé¿å…é¡å¤–è§£é‡‹æˆ–é JSON è¼¸å‡ºã€‚**

    """
    source = llm.invoke(
            [SystemMessage(content=router_instructions)]
            + [
                HumanMessage(
                    content=router_prompt.format(
                        question=question
                    )
                )
            ]
        )
    source = json.loads(source.content)["datasource"]
    print(source)

    if source == "new":
        print("---ROUTE QUESTION TO WEB SEARCH---")
        return "new"
    elif source == "vectorstore":
        print("---ROUTE QUESTION TO RAG---")
        return "vectorstore"
    elif source == "like":
        print("---ROUTE QUESTION TO GENERAL---")
        return "like"

def ready_for_music(state):
    token = get_token()
    name,uri = get_newsongs(token)
    player = play(token,uri) 

def create_a_story(state):
    print("---CREATE A STORY---")
    lyrics = get_lyrics_azlyrics(artist = "ONE OK ROCK", song = "The Pilot </3")
    story_instructions = """
    ä½ æ˜¯ä¸€å€‹å¾ˆæœƒç”¨æ­Œè©èªªæ•…äº‹çš„å°ˆå®¶ã€‚
    è«‹æ ¹æ“šæ­Œè©ç”¨ç¹é«”ä¸­æ–‡èªªä¸€å‰‡èˆ‡æ­Œè©ç›¸é—œçš„æ•…äº‹
    """
    story_prompt = f"""
    æ­Œè©ï¼š{lyrics}
    æ ¹æ“šæ­Œè©çš„å«æ„ï¼Œç”¨ç¹é«”ä¸­æ–‡è¨­è¨ˆä¸€å‰‡èˆ‡è©²ç†å¿µç›¸é—œçš„æ•…äº‹
    æœ€å¾Œåœ¨çµå°¾çš„éƒ¨åˆ†ï¼Œç”¨ä¸€å¥è©±èªªæ˜é€™æ®µæ•…äº‹æƒ³è¡¨é”çš„
    """
    story = llm.invoke(
            [SystemMessage(content=story_instructions)]
            + [
                HumanMessage(
                    content=story_prompt
                )
            ]
        )
    print(story)
    return {"story":story}
    

workflow = StateGraph(GraphState)
workflow.add_node(create_a_story,"create_a_story")
workflow.add_node(general,"general")
workflow.set_conditional_entry_point(
        route_question,
        {
            "new": "create_a_story",
            "vectorstore": END,
            "like": END,
        },
    )
# workflow.add_conditional_edges(
#     first_router,
#         route_question,
#         {
#             "new": "create_a_story",
#             "vectorstore": END,
#             "like": END,
#         },
#     )
workflow.add_edge("create_a_story",END)
graph = workflow.compile()

def show_all(query):
    inputs = {
        "question": query,
        "max_retries": 2,
    }
    try:
        for output in graph.stream(inputs, stream_mode="values"):
            pprint(output)
        return output["story"]
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}ï¼Œè«‹å†è¼¸å…¥ä¸€æ¬¡ã€‚")

# show_all(query="æˆ‘ä»Šå¤©å¿ƒæƒ…å¾ˆå·®")